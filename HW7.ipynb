{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L2NormPenaltyNode(object):\n",
    "    \"\"\" Node computing l2_reg * ||w||^2 for scalars l2_reg and vector w\"\"\"\n",
    "    def __init__(self, l2_reg, w, node_name):\n",
    "        \"\"\" \n",
    "        Parameters:\n",
    "        l2_reg: a scalar value >=0 (not a node)\n",
    "        w: a node for which w.out is a numpy vector\n",
    "        node_name: node's name (a string)\n",
    "        \"\"\"\n",
    "        self.node_name = node_name\n",
    "        self.out = None\n",
    "        self.d_out = None\n",
    "        self.l2_reg = np.array(l2_reg)\n",
    "        self.w = w\n",
    "        self.w_2n=None #2 norm of w\n",
    "        \n",
    "        ## TODO\n",
    "    def forward(self):\n",
    "        self.w_2n=np.dot(self.w.out,self.w.out)\n",
    "        self.out=self.l2_reg*self.w_2n\n",
    "        self.d_out=np.zeros(self.out.shape)\n",
    "        return(self.out)\n",
    "\n",
    "    def backward(self):\n",
    "        #d_l2=self.d_out*self.w_2n\n",
    "        d_w=2*self.d_out*self.l2_reg*self.w.out\n",
    "        #self.l2_reg.d_out+=d_l2 #This should not be used\n",
    "        self.w.d_out+=d_w\n",
    "        return(self.d_out)\n",
    "\n",
    "    def get_predecessors(self):\n",
    "        return([self.w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumNode(object):\n",
    "    \"\"\" Node computing a + b, for numpy arrays a and b\"\"\"\n",
    "    def __init__(self, a, b, node_name):\n",
    "        \"\"\" \n",
    "        Parameters:\n",
    "        a: node for which a.out is a numpy array\n",
    "        b: node for which b.out is a numpy array of the same shape as a\n",
    "        node_name: node's name (a string)\n",
    "        \"\"\"\n",
    "        self.node_name=node_name\n",
    "        self.out=None\n",
    "        self.d_out=None\n",
    "        self.a=a\n",
    "        self.b=b\n",
    "\n",
    "    def forward(self):\n",
    "        self.out=self.a.out+self.b.out\n",
    "        self.d_out=np.zeros(self.out.shape)\n",
    "        return(self.out)\n",
    "\n",
    "    def backward(self):\n",
    "        d_a=self.d_out\n",
    "        d_b=self.d_out\n",
    "        self.a.d_out+=d_a\n",
    "        self.b.d_out+=d_b\n",
    "        return(self.d_out)\n",
    "\n",
    "    def get_predecessors(self):\n",
    "        return([self.a,self.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" Ridge regression with computation graph \"\"\"\n",
    "    def __init__(self, l2_reg=1, step_size=.005,  max_num_epochs = 5000):\n",
    "        self.max_num_epochs = max_num_epochs\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # Build computation graph\n",
    "        self.x = nodes.ValueNode(node_name=\"x\") # to hold a vector input\n",
    "        self.y = nodes.ValueNode(node_name=\"y\") # to hold a scalar response\n",
    "        self.w = nodes.ValueNode(node_name=\"w\") # to hold the parameter vector\n",
    "        self.b = nodes.ValueNode(node_name=\"b\") # to hold the bias parameter (scalar)\n",
    "        self.l2_reg=l2_reg\n",
    "        self.prediction = nodes.VectorScalarAffineNode(x=self.x, w=self.w, b=self.b,\n",
    "                                                 node_name=\"prediction\")\n",
    "        \n",
    "        self.obj_reg = nodes.SquaredL2DistanceNode(a=self.prediction, b=self.y,\n",
    "                                               node_name=\"square loss\")\n",
    "        self.obj_norm = nodes.L2NormPenaltyNode(l2_reg=self.l2_reg, w=self.w,\n",
    "                                               node_name=\"l2 penalty\")\n",
    "        self.objective = nodes.SumNode(a=self.obj_reg, b=self.obj_norm,\n",
    "                                               node_name=\"penalized sq loss\")\n",
    "        # TODO\n",
    "        self.inputs = [self.x]\n",
    "        self.outcomes = [self.y]\n",
    "        self.parameters = [self.w, self.b]\n",
    "        \n",
    "        self.graph = graph.ComputationGraphFunction(self.inputs, self.outcomes,\n",
    "                                                          self.parameters, self.prediction,\n",
    "                                                          self.objective)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python ridge_regression.t.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG: (Node l2 norm node) Max rel error for partial deriv w.r.t. w is 1.86168633954e-09.\n",
    ".DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. a is 5.83867107099e-10.\n",
    "DEBUG: (Node sum node) Max rel error for partial deriv w.r.t. b is 5.83867107099e-10.\n",
    ".DEBUG: (Parameter w) Max rel error for partial deriv 2.40473602971e-09.\n",
    "DEBUG: (Parameter b) Max rel error for partial deriv 4.08892766281e-10.\n",
    ".\n",
    "----------------------------------------------------------------------\n",
    "Ran 3 tests in 0.016s\n",
    "\n",
    "OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python ridge_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch  0 : Ave objective= 1.2045169452292717  Ave training loss:  0.6444665010240027\n",
    "Epoch  50 : Ave objective= 0.31970141440380045  Ave training loss:  0.21304486662737573\n",
    "Epoch  100 : Ave objective= 0.3171781211595713  Ave training loss:  0.20234219039651524\n",
    "Epoch  150 : Ave objective= 0.31792200647600677  Ave training loss:  0.1986326085417778\n",
    "Epoch  200 : Ave objective= 0.31555364999794794  Ave training loss:  0.19733622523602157\n",
    "Epoch  250 : Ave objective= 0.3141917354032541  Ave training loss:  0.1970300851709407\n",
    "Epoch  300 : Ave objective= 0.3149599113865569  Ave training loss:  0.1972961300431405\n",
    "Epoch  350 : Ave objective= 0.31539761927136983  Ave training loss:  0.1969424759746572\n",
    "Epoch  400 : Ave objective= 0.3149355825113064  Ave training loss:  0.19695536368414363\n",
    "Epoch  450 : Ave objective= 0.3149257723553543  Ave training loss:  0.19755819198555208\n",
    "Epoch  500 : Ave objective= 0.3143748880174142  Ave training loss:  0.19825061129835508\n",
    "Epoch  550 : Ave objective= 0.3144449852609848  Ave training loss:  0.19719584311125074\n",
    "Epoch  600 : Ave objective= 0.31062507629508707  Ave training loss:  0.199299239418904\n",
    "Epoch  650 : Ave objective= 0.3117255410064467  Ave training loss:  0.2005090397559372\n",
    "Epoch  700 : Ave objective= 0.30942263153701055  Ave training loss:  0.19807146833640776\n",
    "Epoch  750 : Ave objective= 0.3124756055212761  Ave training loss:  0.19810663127619815\n",
    "Epoch  800 : Ave objective= 0.3095932965062739  Ave training loss:  0.19786532628508663\n",
    "Epoch  850 : Ave objective= 0.3109500662818454  Ave training loss:  0.19914652632701726\n",
    "Epoch  900 : Ave objective= 0.3088824887795819  Ave training loss:  0.19950281000881248\n",
    "Epoch  950 : Ave objective= 0.3099324519403396  Ave training loss:  0.20001079238592748\n",
    "Epoch  1000 : Ave objective= 0.31049802921951913  Ave training loss:  0.20021843414608909\n",
    "Epoch  1050 : Ave objective= 0.30684866969137653  Ave training loss:  0.20302648176139956\n",
    "Epoch  1100 : Ave objective= 0.3109847974070922  Ave training loss:  0.19809911357653875\n",
    "Epoch  1150 : Ave objective= 0.3097733823270748  Ave training loss:  0.1982866757298536\n",
    "Epoch  1200 : Ave objective= 0.3109282768552757  Ave training loss:  0.1991049843180615\n",
    "Epoch  1250 : Ave objective= 0.3095459233898459  Ave training loss:  0.1994572176136299\n",
    "Epoch  1300 : Ave objective= 0.30813565030902507  Ave training loss:  0.1983379068750207\n",
    "Epoch  1350 : Ave objective= 0.3089614635741731  Ave training loss:  0.19885213130554774\n",
    "Epoch  1400 : Ave objective= 0.3094836073944941  Ave training loss:  0.1994393284855249\n",
    "Epoch  1450 : Ave objective= 0.30974514255077745  Ave training loss:  0.1985814980869038\n",
    "Epoch  1500 : Ave objective= 0.30814208396790493  Ave training loss:  0.20292043273591498\n",
    "Epoch  1550 : Ave objective= 0.30886846758298  Ave training loss:  0.1987748096584506\n",
    "Epoch  1600 : Ave objective= 0.3087791955246176  Ave training loss:  0.19899396054691262\n",
    "Epoch  1650 : Ave objective= 0.3084285432777255  Ave training loss:  0.19920623144507374\n",
    "Epoch  1700 : Ave objective= 0.30527483110332737  Ave training loss:  0.20599363046845545\n",
    "Epoch  1750 : Ave objective= 0.3063505827764839  Ave training loss:  0.19909656658496974\n",
    "Epoch  1800 : Ave objective= 0.307740643727055  Ave training loss:  0.20010771479242043\n",
    "Epoch  1850 : Ave objective= 0.3069013027168506  Ave training loss:  0.20006260929216207\n",
    "Epoch  1900 : Ave objective= 0.306720099029395  Ave training loss:  0.19931586647963237\n",
    "Epoch  1950 : Ave objective= 0.3074130285913045  Ave training loss:  0.19997364404047796\n",
    "Epoch  2000 : Ave objective= 0.3069375911843509  Ave training loss:  0.20417287414101845\n",
    "Epoch  0 : Ave objective= 0.6682955044844806  Ave training loss:  0.31977715108244087\n",
    "Epoch  50 : Ave objective= 0.11150390042003569  Ave training loss:  0.12731521620285755\n",
    "Epoch  100 : Ave objective= 0.09147737645588784  Ave training loss:  0.0689850604182719\n",
    "Epoch  150 : Ave objective= 0.07631798774387988  Ave training loss:  0.05493596042933009\n",
    "Epoch  200 : Ave objective= 0.06198226405821661  Ave training loss:  0.04477411610249885\n",
    "Epoch  250 : Ave objective= 0.05783183246203141  Ave training loss:  0.051748462490947576\n",
    "Epoch  300 : Ave objective= 0.05086408060533934  Ave training loss:  0.03584877582512448\n",
    "Epoch  350 : Ave objective= 0.047121533896515855  Ave training loss:  0.032499869020959284\n",
    "Epoch  400 : Ave objective= 0.03874982561360256  Ave training loss:  0.03047541608130463\n",
    "Epoch  450 : Ave objective= 0.03534880889514072  Ave training loss:  0.027313390005803614\n",
    "Epoch  500 : Ave objective= 0.03539027486531891  Ave training loss:  0.037540046563635784"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \\\\\n",
    "When l2_reg=1, average training error is L=0.20417287414101845, with step size=0.00005, 2000 epoches;\\\\\n",
    "When l2_reg=0, average training error is L=0.037540046563635784, with step size=0.0005, 500 epoches;."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RR](Figure_3_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1\n",
    "1.Solution:\\\\\n",
    "Consider $y_r, \\forall r \\in (1,...,m)$:\\\\\n",
    "$$y_r =\\sum_{j=1}^{d} W_{rj}x_{j}+b_r$$\n",
    "So $\\frac{\\partial{y_r}}{\\partial{W_{kj}}}=x_{j}\\ne{0}$ only when $k=r$.\\\\\n",
    "So for $\\frac{\\partial{J}}{\\partial{W_{ij}}}=\\sum_{r=1}^{m}\\frac{\\partial{J}}{\\partial{y_{r}}}\\frac{\\partial{y_r}}{\\partial{W_{ij}}}$, only the item with $r=i$ remains not \"$0$\". We get:\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{W_{ij}}}=\\frac{\\partial{J}}{\\partial{y_{i}}}\\frac{\\partial{y_i}}{\\partial{W_{ij}}}=\\frac{\\partial{J}}{\\partial{y_{i}}}x_{j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Solution:\\\\\n",
    "Based on the rules given in question, item in row i and column j should have expression $\\frac{\\partial{J}}{\\partial{y_{i}}}x_{j}$, which is product of $\\frac{\\partial{J}}{\\partial{y}}[i]$ and $x[j]$.\\\\\n",
    "So the whole matrix $\\frac{\\partial{J}}{\\partial{W}}$ could be expressed as:\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{W}}=\\frac{\\partial{J}}{\\partial{y}}\\otimes x$$\n",
    "Where $\\otimes$ means outer product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Solution:\\\\\n",
    "For $\\forall i \\in (1,...,d)$, \\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{x_{i}}}=\\sum_{k=1}^{m}\\frac{\\partial{J}}{\\partial{y_{k}}}\\frac{\\partial{y_k}}{\\partial{x_{i}}}=\\sum_{k=1}^{m}\\frac{\\partial{J}}{\\partial{y_{k}}}W_{ki}$$\n",
    "So we can rewrite the expression as:\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{x_{i}}}=W_{,i}^{T}(\\frac{\\partial{J}}{\\partial{y}})$$\n",
    "In which $W_{,i}$ is ith column of W.\\\\\n",
    "Thus we get:\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{x}}=W^{T}(\\frac{\\partial{J}}{\\partial{y}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Solution:\\\\\n",
    "Since $b_i$ only appears in $y_i$, for $\\forall{i} \\in (1,...,m)$,\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{b_{i}}}=\\frac{\\partial{J}}{\\partial{y_{i}}} \\frac{\\partial{y_{i}}}{\\partial{b_{i}}}=\\frac{\\partial{J}}{\\partial{y_{i}}}$$\n",
    "So $\\frac{\\partial{J}}{\\partial{b}}=\\frac{\\partial{J}}{\\partial{y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.Solution:\\\\\n",
    "For $\\forall i$ which is a legal entry of $A$, we have:\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{A_{i}}}=\\frac{\\partial{J}}{\\partial{S_{i}}}\\frac{d\\sigma(A_{i})}{d{A_{i}}}$$\n",
    "Considering $i$th entry of $\\sigma^{\\prime}(A)$ is $\\frac{d\\sigma(A_{i})}{d{A_{i}}}$ and $i$th entry of $\\frac{\\partial{J}}{\\partial{S}}$ is $\\frac{\\partial{J}}{\\partial{S_{i}}}$, we get:\\\\\n",
    "$$\\frac{\\partial{J}}{\\partial{A}}=\\frac{\\partial{J}}{\\partial{S}}\\odot{}\\sigma^{\\prime}(A)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffineNode(object):\n",
    "    \"\"\"Node implementing affine transformation (W,x,b)-->Wx+b, where W is a matrix,\n",
    "    and x and b are vectors\n",
    "        Parameters:\n",
    "        W: node for which W.out is a numpy array of shape (m,d)\n",
    "        x: node for which x.out is a numpy array of shape (d)\n",
    "        b: node for which b.out is a numpy array of shape (m) (i.e. vector of length m)\n",
    "    \"\"\"\n",
    "    ## TODO\n",
    "    def __init__(self,W,x,b,node_name):\n",
    "        self.node_name=node_name\n",
    "        self.W=W\n",
    "        self.x=x\n",
    "        self.b=b\n",
    "        self.out=None\n",
    "        self.d_out=None\n",
    "        \n",
    "    def forward(self):\n",
    "        self.out=np.dot(self.W.out,self.x.out)+self.b.out\n",
    "        self.d_out=np.zeros(self.out.shape)\n",
    "        return(self.out)\n",
    "    \n",
    "    def backward(self):\n",
    "        d_W=np.outer(self.d_out,x.out)\n",
    "        d_x=np.dot(W.out.T,self.d_out)\n",
    "        d_b=self.d_out\n",
    "        self.W.d_out+=d_W\n",
    "        self.x.d_out+=d_x\n",
    "        self.b.d_out+=d_b\n",
    "        return(self.d_out)\n",
    "    \n",
    "    def get_predecessors(self):\n",
    "        return([self.W,self.x,self.b])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TanhNode(object):\n",
    "    \"\"\"Node tanh(a), where tanh is applied elementwise to the array a\n",
    "        Parameters:\n",
    "        a: node for which a.out is a numpy array\n",
    "    \"\"\"\n",
    "    ## TODO\n",
    "    def __init__(self,a,node_name):\n",
    "        self.node_name=node_name\n",
    "        self.a=a\n",
    "        self.out=None\n",
    "        self.d_out=None\n",
    "        self.tanh_a=None\n",
    "        \n",
    "    def forward(self):\n",
    "        self.tanh_a=np.tanh(a.out)\n",
    "        self.out=self.tanh_a\n",
    "        self.d_out=np.zeros(self.out.shape)\n",
    "        return(self.out)\n",
    "    \n",
    "    def backward(self):\n",
    "        d_a=self.d_out*(1-self.tanh_a**2) ##this might cause problem\n",
    "        self.a.d_out+=d_a\n",
    "        return(self.d_out)\n",
    "    \n",
    "    def get_predecessors(self):\n",
    "        return([self.a])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegression(BaseEstimator, RegressorMixin):\n",
    "    \"\"\" MLP regression with computation graph \"\"\"\n",
    "    def __init__(self, num_hidden_units=10, step_size=.005, init_param_scale=0.01, max_num_epochs = 5000):\n",
    "        self.num_hidden_units = num_hidden_units\n",
    "        self.init_param_scale = 0.01\n",
    "        self.max_num_epochs = max_num_epochs\n",
    "        self.step_size = step_size\n",
    "\n",
    "        # Build computation graph\n",
    "        self.x = nodes.ValueNode(node_name=\"x\") # to hold a vector input\n",
    "        self.y = nodes.ValueNode(node_name=\"y\") # to hold a scalar response\n",
    "        self.w1= nodes.ValueNode(node_name=\"w1\")\n",
    "        self.w2= nodes.ValueNode(node_name=\"w2\")\n",
    "        self.b1= nodes.ValueNode(node_name=\"b1\")\n",
    "        self.b2= nodes.ValueNode(node_name=\"b2\")\n",
    "        \n",
    "        ## TODO\n",
    "        self.hid_1 = nodes.AffineNode(W=self.w1,x=self.x,b=self.b1,\n",
    "                                      node_name=\"hidden1\")\n",
    "        self.hid_2 = nodes.TanhNode(a=self.hid_1,\n",
    "                                    node_name=\"hidden2\")\n",
    "        \n",
    "        self.prediction = nodes.VectorScalarAffineNode(x=self.hid_2, w=self.w2, b=self.b2,\n",
    "                                                       node_name=\"prediction\")\n",
    "        \n",
    "        self.objective = nodes.SquaredL2DistanceNode(a=self.prediction, b=self.y,\n",
    "                                                     node_name=\"objective\")\n",
    "        # TODO\n",
    "        self.inputs = [self.x]\n",
    "        self.outcomes = [self.y]\n",
    "        self.parameters = [self.w1, self.b1,self.w2,self.b2]\n",
    "        \n",
    "        self.graph = graph.ComputationGraphFunction(self.inputs, self.outcomes,\n",
    "                                                          self.parameters, self.prediction,\n",
    "                                                          self.objective)\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_instances, num_ftrs = X.shape\n",
    "        y = y.reshape(-1)\n",
    "\n",
    "        ## TODO: Initialize parameters (small random numbers -- not all 0, to break symmetry )\n",
    "        s = self.init_param_scale\n",
    "        init_values = {\"w1\": np.random.uniform(-s,s,[self.num_hidden_units,num_ftrs]), \n",
    "                       \"b1\": np.random.uniform(-s,s,self.num_hidden_units),\n",
    "                       \"w2\": np.random.uniform(-s,s,[self.num_hidden_units]),\n",
    "                       \"b2\": np.array(np.random.uniform(-s,s))}\n",
    "\n",
    "        self.graph.set_parameters(init_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python mlp_regression.t.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. W is 1.4262984833515724e-08.\n",
    "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. x is 8.223950139381322e-10.\n",
    "DEBUG: (Node affine) Max rel error for partial deriv w.r.t. b is 5.838672051389452e-10.\n",
    ".DEBUG: (Node tanh) Max rel error for partial deriv w.r.t. a is 3.080940169299588e-09.\n",
    ".DEBUG: (Parameter w1) Max rel error for partial deriv 2.567900441046858e-08.\n",
    "DEBUG: (Parameter b1) Max rel error for partial deriv 3.25437097957294e-09.\n",
    "DEBUG: (Parameter w2) Max rel error for partial deriv 1.3454349429215027e-09.\n",
    "DEBUG: (Parameter b2) Max rel error for partial deriv 2.675577833559226e-11.\n",
    ".\n",
    "----------------------------------------------------------------------\n",
    "Ran 3 tests in 0.034s\n",
    "\n",
    "OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "python mlp_regression.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch  0 : Ave objective= 3.1591014751860076  Ave training loss:  2.7362316589545106\n",
    "Epoch  50 : Ave objective= 0.7677350306022097  Ave training loss:  0.7597321419094898\n",
    "Epoch  100 : Ave objective= 0.7461508386700006  Ave training loss:  0.7383849331389437\n",
    "Epoch  150 : Ave objective= 0.719311408427905  Ave training loss:  0.7128619465324326\n",
    "Epoch  200 : Ave objective= 0.6980911075326794  Ave training loss:  0.6913386280159942\n",
    "Epoch  250 : Ave objective= 0.6830844325382043  Ave training loss:  0.6762676687496626\n",
    "Epoch  300 : Ave objective= 0.6714060188571502  Ave training loss:  0.6634604246237308\n",
    "Epoch  350 : Ave objective= 0.6541378542243406  Ave training loss:  0.6450006018953023\n",
    "Epoch  400 : Ave objective= 0.6200928004489193  Ave training loss:  0.6082772788821091\n",
    "Epoch  450 : Ave objective= 0.5545834370722189  Ave training loss:  0.5412474669166243\n",
    "Epoch  500 : Ave objective= 0.4580432769599757  Ave training loss:  0.45666634644796106\n",
    "Epoch  550 : Ave objective= 0.38070944512720273  Ave training loss:  0.3658963600990613\n",
    "Epoch  600 : Ave objective= 0.3378834629111795  Ave training loss:  0.32479274088199434\n",
    "Epoch  650 : Ave objective= 0.3175627603487417  Ave training loss:  0.3051663258487649\n",
    "Epoch  700 : Ave objective= 0.30666700002034897  Ave training loss:  0.29380197216678694\n",
    "Epoch  750 : Ave objective= 0.29646349086808316  Ave training loss:  0.28612347707394126\n",
    "Epoch  800 : Ave objective= 0.29103442246795913  Ave training loss:  0.27976206489276484\n",
    "Epoch  850 : Ave objective= 0.2824046999110614  Ave training loss:  0.282547929657588\n",
    "Epoch  900 : Ave objective= 0.2793105988587881  Ave training loss:  0.2715173228187371\n",
    "Epoch  950 : Ave objective= 0.27608032367616686  Ave training loss:  0.26767653188257556\n",
    "Epoch  1000 : Ave objective= 0.2751000909381586  Ave training loss:  0.26416295953010066\n",
    "Epoch  1050 : Ave objective= 0.2681974433967226  Ave training loss:  0.26725609468174455\n",
    "Epoch  1100 : Ave objective= 0.2696226075116502  Ave training loss:  0.2591101217527617\n",
    "Epoch  1150 : Ave objective= 0.2607295925635616  Ave training loss:  0.2666777085632656\n",
    "Epoch  1200 : Ave objective= 0.2656294144535176  Ave training loss:  0.2552224969126479\n",
    "Epoch  1250 : Ave objective= 0.26235826647843574  Ave training loss:  0.2548450287733928\n",
    "Epoch  1300 : Ave objective= 0.25976796325219437  Ave training loss:  0.25216323080752223\n",
    "Epoch  1350 : Ave objective= 0.261221434512845  Ave training loss:  0.25027387653820304\n",
    "Epoch  1400 : Ave objective= 0.2574181243331116  Ave training loss:  0.24914241014187624\n",
    "Epoch  1450 : Ave objective= 0.2549377809310199  Ave training loss:  0.24872880997017105\n",
    "Epoch  1500 : Ave objective= 0.2556442907263385  Ave training loss:  0.24600707423543533\n",
    "Epoch  1550 : Ave objective= 0.25247666423693926  Ave training loss:  0.24514991456690893\n",
    "Epoch  1600 : Ave objective= 0.25280092843280466  Ave training loss:  0.24446438491356356\n",
    "Epoch  1650 : Ave objective= 0.25205544380484335  Ave training loss:  0.24244241849597511\n",
    "Epoch  1700 : Ave objective= 0.2492364668785854  Ave training loss:  0.2414931271124457\n",
    "Epoch  1750 : Ave objective= 0.24948454109422394  Ave training loss:  0.2403078583712665\n",
    "Epoch  1800 : Ave objective= 0.24907863996663449  Ave training loss:  0.2395164444195047\n",
    "Epoch  1850 : Ave objective= 0.24720406224290262  Ave training loss:  0.23833205163304017\n",
    "Epoch  1900 : Ave objective= 0.2467927813499694  Ave training loss:  0.2374864407913448\n",
    "Epoch  1950 : Ave objective= 0.24615715588218148  Ave training loss:  0.2375493489361685\n",
    "Epoch  2000 : Ave objective= 0.24557643554055558  Ave training loss:  0.2361426301619667\n",
    "Epoch  2050 : Ave objective= 0.24444023044003804  Ave training loss:  0.23517585750580308\n",
    "Epoch  2100 : Ave objective= 0.234992340921919  Ave training loss:  0.256770928611745\n",
    "Epoch  2150 : Ave objective= 0.24097537283035275  Ave training loss:  0.23957957896011148\n",
    "Epoch  2200 : Ave objective= 0.2424078299557825  Ave training loss:  0.23278531929323765\n",
    "Epoch  2250 : Ave objective= 0.24151120404933007  Ave training loss:  0.23273181967510606\n",
    "Epoch  2300 : Ave objective= 0.24064912747130932  Ave training loss:  0.2314191431602656\n",
    "Epoch  2350 : Ave objective= 0.24017443533055066  Ave training loss:  0.2311178773721087\n",
    "Epoch  2400 : Ave objective= 0.23766120070278934  Ave training loss:  0.23610280426471905\n",
    "Epoch  2450 : Ave objective= 0.23907538550925864  Ave training loss:  0.23029465255453144\n",
    "Epoch  2500 : Ave objective= 0.23872708102801674  Ave training loss:  0.22939404702984154\n",
    "Epoch  2550 : Ave objective= 0.23875667347935967  Ave training loss:  0.22903072133273322\n",
    "Epoch  2600 : Ave objective= 0.23825894895085173  Ave training loss:  0.22891609779976763\n",
    "Epoch  2650 : Ave objective= 0.23645260183189015  Ave training loss:  0.2278801900016521\n",
    "Epoch  2700 : Ave objective= 0.23688191813881349  Ave training loss:  0.22872950884388285\n",
    "Epoch  2750 : Ave objective= 0.2368524019353053  Ave training loss:  0.2267836969537594\n",
    "Epoch  2800 : Ave objective= 0.23613543373853713  Ave training loss:  0.22639368249372263\n",
    "Epoch  2850 : Ave objective= 0.23206251338006062  Ave training loss:  0.2293831843240886\n",
    "Epoch  2900 : Ave objective= 0.2359771883386923  Ave training loss:  0.2277829995363427\n",
    "Epoch  2950 : Ave objective= 0.23590991816118645  Ave training loss:  0.22493178307132158\n",
    "Epoch  3000 : Ave objective= 0.23542061499215244  Ave training loss:  0.2260919038845546\n",
    "Epoch  3050 : Ave objective= 0.2342423764505519  Ave training loss:  0.22727633857190604\n",
    "Epoch  3100 : Ave objective= 0.2334156628172298  Ave training loss:  0.2243824089692325\n",
    "Epoch  3150 : Ave objective= 0.23437685086322335  Ave training loss:  0.22398457898870341\n",
    "Epoch  3200 : Ave objective= 0.23209204812936374  Ave training loss:  0.2235162857803013\n",
    "Epoch  3250 : Ave objective= 0.22997572847212325  Ave training loss:  0.22415495816414613\n",
    "Epoch  3300 : Ave objective= 0.22991050713614317  Ave training loss:  0.22442779815868424\n",
    "Epoch  3350 : Ave objective= 0.23005510607554158  Ave training loss:  0.22224845621985825\n",
    "Epoch  3400 : Ave objective= 0.23028696498496384  Ave training loss:  0.22140010145520012\n",
    "Epoch  3450 : Ave objective= 0.22931852362344685  Ave training loss:  0.22902067015465444\n",
    "Epoch  3500 : Ave objective= 0.22957896508995426  Ave training loss:  0.22267647851399947\n",
    "Epoch  3550 : Ave objective= 0.22706335651349627  Ave training loss:  0.23117005125160314\n",
    "Epoch  3600 : Ave objective= 0.23048217661074774  Ave training loss:  0.22046462503550546\n",
    "Epoch  3650 : Ave objective= 0.22940338477432742  Ave training loss:  0.22017283439342297\n",
    "Epoch  3700 : Ave objective= 0.22637328399642595  Ave training loss:  0.22040402012195418\n",
    "Epoch  3750 : Ave objective= 0.2244326384162156  Ave training loss:  0.22710892098956006\n",
    "Epoch  3800 : Ave objective= 0.22655219698981288  Ave training loss:  0.22084215594422518\n",
    "Epoch  3850 : Ave objective= 0.22877055614824993  Ave training loss:  0.2182947968361353\n",
    "Epoch  3900 : Ave objective= 0.2263906386312643  Ave training loss:  0.21947057783264134\n",
    "Epoch  3950 : Ave objective= 0.22371801690593807  Ave training loss:  0.21935790183164802\n",
    "Epoch  4000 : Ave objective= 0.22753503254247312  Ave training loss:  0.21863518284860783\n",
    "Epoch  4050 : Ave objective= 0.22490957323261643  Ave training loss:  0.21723571613570591\n",
    "Epoch  4100 : Ave objective= 0.2246669690937707  Ave training loss:  0.22011200907616793\n",
    "Epoch  4150 : Ave objective= 0.22614676264411315  Ave training loss:  0.21587162046843894\n",
    "Epoch  4200 : Ave objective= 0.22066982660672643  Ave training loss:  0.2324253937044383\n",
    "Epoch  4250 : Ave objective= 0.2246824147153844  Ave training loss:  0.21780994388517072\n",
    "Epoch  4300 : Ave objective= 0.22442736211454073  Ave training loss:  0.21492488122364378\n",
    "Epoch  4350 : Ave objective= 0.22396937597380454  Ave training loss:  0.2146660699525994\n",
    "Epoch  4400 : Ave objective= 0.220481878901154  Ave training loss:  0.21993178013200865\n",
    "Epoch  4450 : Ave objective= 0.22353240666437516  Ave training loss:  0.21657812054073208\n",
    "Epoch  4500 : Ave objective= 0.22350226396873993  Ave training loss:  0.21339918081826498\n",
    "Epoch  4550 : Ave objective= 0.22054503158845887  Ave training loss:  0.21603987294123603\n",
    "Epoch  4600 : Ave objective= 0.22247053435413858  Ave training loss:  0.2130819919645474\n",
    "Epoch  4650 : Ave objective= 0.2171009682815295  Ave training loss:  0.21875913020778456\n",
    "Epoch  4700 : Ave objective= 0.2204143408087334  Ave training loss:  0.2151291276816613\n",
    "Epoch  4750 : Ave objective= 0.2193323869075738  Ave training loss:  0.2190749525253178\n",
    "Epoch  4800 : Ave objective= 0.22149604139809578  Ave training loss:  0.211560455500563\n",
    "Epoch  4850 : Ave objective= 0.22138332401187275  Ave training loss:  0.21138296555540767\n",
    "Epoch  4900 : Ave objective= 0.22023782115347598  Ave training loss:  0.2125850615323971\n",
    "Epoch  4950 : Ave objective= 0.21989305650334864  Ave training loss:  0.21275587960182216\n",
    "Epoch  5000 : Ave objective= 0.2194938001229822  Ave training loss:  0.21088639477651444\n",
    "Epoch  0 : Ave objective= 2.5391353049254115  Ave training loss:  1.185301968326381\n",
    "Epoch  50 : Ave objective= 0.11578914352391281  Ave training loss:  0.1180625025132354\n",
    "Epoch  100 : Ave objective= 0.09267584418118249  Ave training loss:  0.07897920418454332\n",
    "Epoch  150 : Ave objective= 0.07791311716751997  Ave training loss:  0.060736271339982564\n",
    "Epoch  200 : Ave objective= 0.06728620454979899  Ave training loss:  0.052556983728144095\n",
    "Epoch  250 : Ave objective= 0.06105088153134284  Ave training loss:  0.05030195651642041\n",
    "Epoch  300 : Ave objective= 0.05004994044825338  Ave training loss:  0.06764223540773093\n",
    "Epoch  350 : Ave objective= 0.04745820564971187  Ave training loss:  0.03316839555456963\n",
    "Epoch  400 : Ave objective= 0.046591797226093655  Ave training loss:  0.028595487466373817\n",
    "Epoch  450 : Ave objective= 0.03590279129011667  Ave training loss:  0.052615892978353146\n",
    "Epoch  500 : Ave objective= 0.03484356303899753  Ave training loss:  0.027027353055170858"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: \\\\\n",
    "When initial parameter sample threshold=0.0005, average training error is L=0.21088639477651444 with step size=0.001, 5000 epoches;\\\\\n",
    "When initial parameter sample threshold=0.01, average training error is L=0.027027353055170858 with step size=0.0005, 500 epoches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MLP fitting](Figure_4_2_3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    print('Thank you all staff in DS-GA 1003 ML!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00329486, -0.03578585,  0.00206359, -0.05185712,  0.06492482])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.uniform(-0.1,0.1,[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
